{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from forexgym.utils import Query, available_timeframes, Timeframe, CurrencyPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_processor(df: pd.DataFrame, time_column: str = \"Date\", *args, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "            Drops the <time_column> column from an OHLC DataFrame. Default manipulation if no data_processor is provided in a query.\n",
    "\n",
    "            Parameters:\n",
    "                df (pd.DataFrame): The DataFrame from which to drop the <time_column> column.\n",
    "                time_column (str): The name of the column to drop.\n",
    "            \n",
    "            Returns:\n",
    "                pd.DataFrame: The OHLC with the <time_column> column removed.\n",
    "        \"\"\"\n",
    "        \n",
    "        return df.drop([time_column], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_datasets(query: Query, timeframes: Dict[str, pd.DataFrame], time_column: str = \"Date\", *args, **kwargs) -> None:\n",
    "        \n",
    "    trading_timeframe_lable = query.trading_timeframe\n",
    "    trading_timeframe = available_timeframes[trading_timeframe_lable]\n",
    "    trading_column = query.trading_column\n",
    "    \n",
    "    trading_df = timeframes[trading_timeframe_lable]\n",
    "    \n",
    "    \n",
    "    episode_data = pd.DataFrame()\n",
    "    episode_data[time_column] = trading_df[time_column]\n",
    "    episode_data[\"Trading_Price\"] = trading_df[trading_column] # TODO: Include OHLC\n",
    "    \n",
    "    \n",
    "    \n",
    "    for query_params in query.queries:\n",
    "        query_timeframe: Timeframe = query_params[\"timeframe\"]\n",
    "        window_size: int = query_params[\"window_size\"]\n",
    "        data_processor: Callable[[pd.DataFrame], pd.DataFrame] = query_params.get(\"data_processor\", default_processor)\n",
    "        \n",
    "        # Selects the query dataframe\n",
    "        query_df = timeframes[query_timeframe.lable]\n",
    "        \n",
    "        # Extracts features from the query dataframe\n",
    "        processed_df = data_processor(query_df)\n",
    "        \n",
    "        # Creates a dataframe in which all rows contain all the features\n",
    "        stacked = pd.concat([processed_df.add_suffix(f\"_{shift}\").shift(shift) for shift in range(window_size)], axis=1)\n",
    "        \n",
    "        # Smaller or equal than the trading TF\n",
    "        if trading_timeframe >= query_timeframe:\n",
    "            \n",
    "            # Uses the existing dates in the trading dataframe to be included in the final datasets since all the other rows are irrelevant and will be discarded\n",
    "            valid = query_df[time_column].isin(trading_df[time_column])\n",
    "            \n",
    "            # Selects the relevant rows (rows which share dates), adds a prefix and adds them to the final dataset\n",
    "            filtered: pd.DataFrame = stacked[valid].reset_index(drop=True).add_prefix(f\"{query_timeframe.lable}_\")\n",
    "            episode_data = pd.concat([episode_data, filtered], axis=1)\n",
    "        \n",
    "        # Greater TF than the trading TF \n",
    "        else:\n",
    "            # Returns a pd.Series in which all dates of the trading dataframe have been rounded down to match that of the query (e.g. 12:00 -> 12:00, 12:15 -> 12:00, 12:30 -> 12:00, 12:45 -> 12:00)\n",
    "            trading_dates = trading_df[time_column].copy().dt.floor(query_timeframe.value)\n",
    "            \n",
    "            # Includes the Date column back into the feature dataframe to be compared (the user probably has removed Date column from features)\n",
    "            stacked[time_column] = query_df[time_column]\n",
    "            \n",
    "            # Given the trading dates (a series with Query Tf/Trading Tf n repeated rows 1H/15m = 4 repeated rows)\n",
    "            # For each row (date) in trading dates the corresponding row (date) in the stacked dataframe is merged with the corresponding row (date) in the stacked dataframe such that the two rows share the same date\n",
    "            # It therefore yields a dataframe consisting of merged rows with the same date so that for all divisiones in the trading TF it has data from the higher TFs\n",
    "            # It is shifted n times to avoid lookahead bias\n",
    "            # Ik its a bit confusing but it works\n",
    "            \n",
    "            \n",
    "            filtered = pd.merge(trading_dates, stacked, on=time_column, how='outer').drop([time_column], axis=1).add_prefix(f\"{query_timeframe.lable}_\").shift(int(query_timeframe.value/trading_timeframe.value))\n",
    "            \n",
    "            # Filtered TF added horizontaly into the final dataset\n",
    "            episode_data = pd.concat([episode_data, filtered], axis=1)\n",
    "    \n",
    "   \n",
    "    episode_data = episode_data.dropna().reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return episode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_close(df: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:\n",
    "    \n",
    "    return pd.DataFrame(df[\"Close\"])\n",
    "\n",
    "def select_date(df: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:\n",
    "    \n",
    "    return df.drop([\"Open\", \"High\", \"Low\"], axis=1)\n",
    "\n",
    "def article_processor(df: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:\n",
    "    df[\"x1\"] = ((df[\"Close\"] - df[\"Close\"].shift(1) ) / df[\"Close\"]).shift(1) \n",
    "    df[\"x2\"] = ((df[\"High\"] - df[\"High\"].shift(1) ) / df[\"High\"]).shift(1) \n",
    "    df[\"x3\"] = ((df[\"Low\"] - df[\"Low\"].shift(1) ) / df[\"Low\"]).shift(1) \n",
    "    df[\"x4\"] = (df[\"High\"] - df[\"Close\"]) / df[\"Close\"] \n",
    "    df[\"x5\"] = (df[\"Close\"] - df[\"Low\"]) / df[\"Close\"] \n",
    "\n",
    "    return df.drop([\"Open\", \"High\", \"Low\", \"Date\", \"Close\"], axis=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Trading_Price</th>\n",
       "      <th>1H_Date_0</th>\n",
       "      <th>1H_Close_0</th>\n",
       "      <th>1H_Date_1</th>\n",
       "      <th>1H_Close_1</th>\n",
       "      <th>15m_Date_0</th>\n",
       "      <th>15m_Close_0</th>\n",
       "      <th>15m_Date_1</th>\n",
       "      <th>15m_Close_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-20 02:00:00+00:00</td>\n",
       "      <td>1.06898</td>\n",
       "      <td>2023-09-20 01:00:00+00:00</td>\n",
       "      <td>1.06864</td>\n",
       "      <td>2023-09-20 00:00:00+00:00</td>\n",
       "      <td>1.06850</td>\n",
       "      <td>2023-09-20 02:00:00+00:00</td>\n",
       "      <td>1.06898</td>\n",
       "      <td>2023-09-20 01:45:00+00:00</td>\n",
       "      <td>1.06864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-20 02:15:00+00:00</td>\n",
       "      <td>1.06862</td>\n",
       "      <td>2023-09-20 01:00:00+00:00</td>\n",
       "      <td>1.06864</td>\n",
       "      <td>2023-09-20 00:00:00+00:00</td>\n",
       "      <td>1.06850</td>\n",
       "      <td>2023-09-20 02:15:00+00:00</td>\n",
       "      <td>1.06862</td>\n",
       "      <td>2023-09-20 02:00:00+00:00</td>\n",
       "      <td>1.06898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-20 02:30:00+00:00</td>\n",
       "      <td>1.06856</td>\n",
       "      <td>2023-09-20 01:00:00+00:00</td>\n",
       "      <td>1.06864</td>\n",
       "      <td>2023-09-20 00:00:00+00:00</td>\n",
       "      <td>1.06850</td>\n",
       "      <td>2023-09-20 02:30:00+00:00</td>\n",
       "      <td>1.06856</td>\n",
       "      <td>2023-09-20 02:15:00+00:00</td>\n",
       "      <td>1.06862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-20 02:45:00+00:00</td>\n",
       "      <td>1.06832</td>\n",
       "      <td>2023-09-20 01:00:00+00:00</td>\n",
       "      <td>1.06864</td>\n",
       "      <td>2023-09-20 00:00:00+00:00</td>\n",
       "      <td>1.06850</td>\n",
       "      <td>2023-09-20 02:45:00+00:00</td>\n",
       "      <td>1.06832</td>\n",
       "      <td>2023-09-20 02:30:00+00:00</td>\n",
       "      <td>1.06856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-20 03:00:00+00:00</td>\n",
       "      <td>1.06824</td>\n",
       "      <td>2023-09-20 02:00:00+00:00</td>\n",
       "      <td>1.06832</td>\n",
       "      <td>2023-09-20 01:00:00+00:00</td>\n",
       "      <td>1.06864</td>\n",
       "      <td>2023-09-20 03:00:00+00:00</td>\n",
       "      <td>1.06824</td>\n",
       "      <td>2023-09-20 02:45:00+00:00</td>\n",
       "      <td>1.06832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  Trading_Price                 1H_Date_0  \\\n",
       "0 2023-09-20 02:00:00+00:00        1.06898 2023-09-20 01:00:00+00:00   \n",
       "1 2023-09-20 02:15:00+00:00        1.06862 2023-09-20 01:00:00+00:00   \n",
       "2 2023-09-20 02:30:00+00:00        1.06856 2023-09-20 01:00:00+00:00   \n",
       "3 2023-09-20 02:45:00+00:00        1.06832 2023-09-20 01:00:00+00:00   \n",
       "4 2023-09-20 03:00:00+00:00        1.06824 2023-09-20 02:00:00+00:00   \n",
       "\n",
       "   1H_Close_0                 1H_Date_1  1H_Close_1                15m_Date_0  \\\n",
       "0     1.06864 2023-09-20 00:00:00+00:00     1.06850 2023-09-20 02:00:00+00:00   \n",
       "1     1.06864 2023-09-20 00:00:00+00:00     1.06850 2023-09-20 02:15:00+00:00   \n",
       "2     1.06864 2023-09-20 00:00:00+00:00     1.06850 2023-09-20 02:30:00+00:00   \n",
       "3     1.06864 2023-09-20 00:00:00+00:00     1.06850 2023-09-20 02:45:00+00:00   \n",
       "4     1.06832 2023-09-20 01:00:00+00:00     1.06864 2023-09-20 03:00:00+00:00   \n",
       "\n",
       "   15m_Close_0                15m_Date_1  15m_Close_1  \n",
       "0      1.06898 2023-09-20 01:45:00+00:00      1.06864  \n",
       "1      1.06862 2023-09-20 02:00:00+00:00      1.06898  \n",
       "2      1.06856 2023-09-20 02:15:00+00:00      1.06862  \n",
       "3      1.06832 2023-09-20 02:30:00+00:00      1.06856  \n",
       "4      1.06824 2023-09-20 02:45:00+00:00      1.06832  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#timeframes = [\"1m\", \"5m\", \"15m\", \"30m\", \"1H\", \"4H\", \"1D\"]\n",
    "used_timeframes = [\"15m\", \"1H\"]\n",
    "    \n",
    "query = Query(episode_length=256, trading_timeframe=\"15m\", trading_column=\"Close\")\n",
    "# query.add_query(\n",
    "#     timeframe=\"4H\",\n",
    "#     window_size=4,#     data_processor=article_processor\n",
    "# )\n",
    "query.add_query(\n",
    "    timeframe=\"1H\",\n",
    "    window_size=2,\n",
    "    data_processor=select_date\n",
    ")\n",
    "query.add_query(\n",
    "    timeframe=\"15m\",window_size=2,\n",
    "    data_processor=select_date\n",
    ")\n",
    "\n",
    "timeframes = CurrencyPair(ticker=\"EURUSD\", timeframes=used_timeframes).timeframes\n",
    "\n",
    "\n",
    "format_datasets(query, timeframes).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.06835\n",
       "1        1.06837\n",
       "2        1.06850\n",
       "3        1.06851\n",
       "4        1.06852\n",
       "          ...   \n",
       "25074    1.11581\n",
       "25075    1.11577\n",
       "25076    1.11629\n",
       "25077    1.11641\n",
       "25078        NaN\n",
       "Name: Close, Length: 25079, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeframes[\"15m\"][\"Close\"].shift(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
