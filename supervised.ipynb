{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from forexgym.utils import Query\n",
    "from forexgym.envs import DiscreteActionEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated EURUSD dataset.\n"
     ]
    }
   ],
   "source": [
    "def article_processor(df: pd.DataFrame, *args, **kwargs) -> pd.DataFrame:\n",
    "    df[\"x1\"] = ((df[\"Close\"] - df[\"Close\"].shift(1) ) / df[\"Close\"]).shift(1) \n",
    "    df[\"x2\"] = ((df[\"High\"] - df[\"High\"].shift(1) ) / df[\"High\"]).shift(1) \n",
    "    df[\"x3\"] = ((df[\"Low\"] - df[\"Low\"].shift(1) ) / df[\"Low\"]).shift(1) \n",
    "    df[\"x4\"] = (df[\"High\"] - df[\"Close\"]) / df[\"Close\"] \n",
    "    df[\"x5\"] = (df[\"Close\"] - df[\"Low\"]) / df[\"Close\"] \n",
    "    \n",
    "    return df.drop([\"Date\", \"Open\", \"High\", \"Low\", \"Close\"], axis=1)\n",
    "\n",
    "ticker = \"EURUSD\"\n",
    "#timeframes = [\"1m\", \"5m\", \"15m\", \"30m\", \"1H\", \"4H\", \"1D\"]\n",
    "timeframes = [\"15m\", \"1H\"]\n",
    "\n",
    "query = Query(episode_length=256, trading_timeframe=\"15m\", trading_column=\"Close\")\n",
    "# query.add_query(\n",
    "#     timeframe=\"4H\",\n",
    "#     window_size=4,\n",
    "#     data_processor=article_processor\n",
    "# )\n",
    "query.add_query(\n",
    "    timeframe=\"15m\",\n",
    "    window_size=16,\n",
    "    data_processor=article_processor\n",
    ")\n",
    "query.add_query(\n",
    "    timeframe=\"1H\",\n",
    "    window_size=4,\n",
    "    data_processor=article_processor\n",
    ")\n",
    "# query.add_query(\n",
    "#     timeframe=\"15m\",\n",
    "#     window_size=4,\n",
    "#     data_processor=article_processor\n",
    "# )\n",
    "# dataset = pair.generate_dataset(query)\n",
    "\n",
    "env = DiscreteActionEnvironment(\n",
    "    currency_tickers={\"EURUSD\": timeframes},\n",
    "    query=query,\n",
    "    reward_type=\"continuous\",\n",
    "    reward_multiplier=1e3,\n",
    "    episode_length=256,\n",
    "    allow_holding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, n_inputs: int, n_outputs: int, hidden_size: int = 128, n_layers: int = 2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden_size),\n",
    "            *[\n",
    "                nn.ReLU() if i % 2 == 0 else nn.Linear(hidden_size, hidden_size) for i in range(n_layers*2)\n",
    "            ],\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_outputs),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: th.Tensor) -> th.Tensor:\n",
    "        return self.softmax(self.layers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Trading_Price</th>\n",
       "      <th>15m_x1_0</th>\n",
       "      <th>15m_x2_0</th>\n",
       "      <th>15m_x3_0</th>\n",
       "      <th>15m_x4_0</th>\n",
       "      <th>15m_x5_0</th>\n",
       "      <th>15m_x1_1</th>\n",
       "      <th>15m_x2_1</th>\n",
       "      <th>15m_x3_1</th>\n",
       "      <th>...</th>\n",
       "      <th>1H_x2_2</th>\n",
       "      <th>1H_x3_2</th>\n",
       "      <th>1H_x4_2</th>\n",
       "      <th>1H_x5_2</th>\n",
       "      <th>1H_x1_3</th>\n",
       "      <th>1H_x2_3</th>\n",
       "      <th>1H_x3_3</th>\n",
       "      <th>1H_x4_3</th>\n",
       "      <th>1H_x5_3</th>\n",
       "      <th>Lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-20 06:00:00+00:00</td>\n",
       "      <td>1.06866</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-20 06:15:00+00:00</td>\n",
       "      <td>1.06902</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-20 06:30:00+00:00</td>\n",
       "      <td>1.06926</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-20 06:45:00+00:00</td>\n",
       "      <td>1.06820</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-20 07:00:00+00:00</td>\n",
       "      <td>1.06769</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000609</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  Trading_Price  15m_x1_0  15m_x2_0  15m_x3_0  \\\n",
       "0  2023-09-20 06:00:00+00:00        1.06866 -0.000056 -0.000225 -0.000159   \n",
       "1  2023-09-20 06:15:00+00:00        1.06902  0.000515  0.000580 -0.000581   \n",
       "2  2023-09-20 06:30:00+00:00        1.06926  0.000337  0.000355  0.001217   \n",
       "3  2023-09-20 06:45:00+00:00        1.06820  0.000224  0.000112  0.000178   \n",
       "4  2023-09-20 07:00:00+00:00        1.06769 -0.000992  0.000028 -0.000609   \n",
       "\n",
       "   15m_x4_0  15m_x5_0  15m_x1_1  15m_x2_1  15m_x3_1  ...   1H_x2_2   1H_x3_2  \\\n",
       "0  0.000122  0.001263  0.000037  0.000215  0.000187  ...  0.000206  0.000253   \n",
       "1  0.000140  0.000384 -0.000056 -0.000225 -0.000159  ...  0.000206  0.000253   \n",
       "2  0.000028  0.000430  0.000515  0.000580 -0.000581  ...  0.000206  0.000253   \n",
       "3  0.001048  0.000047  0.000337  0.000355  0.001217  ...  0.000206  0.000253   \n",
       "4  0.000693  0.000009  0.000224  0.000112  0.000178  ... -0.000515 -0.000421   \n",
       "\n",
       "    1H_x4_2   1H_x5_2   1H_x1_3   1H_x2_3   1H_x3_3   1H_x4_3   1H_x5_3  Lable  \n",
       "0  0.000440  0.000122  0.000131  0.000159  0.000066  0.000627  0.000028      1  \n",
       "1  0.000440  0.000122  0.000131  0.000159  0.000066  0.000627  0.000028      1  \n",
       "2  0.000440  0.000122  0.000131  0.000159  0.000066  0.000627  0.000028      0  \n",
       "3  0.000440  0.000122  0.000131  0.000159  0.000066  0.000627  0.000028      0  \n",
       "4  0.000234  0.000037 -0.000300  0.000206  0.000253  0.000440  0.000122      1  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/training/EURUSD.csv\")\n",
    "df[\"Lable\"] = (df[\"Trading_Price\"].shift(-1)-df[\"Trading_Price\"]).apply(lambda x: 1 if x > 0 else 0)\n",
    "df = df.dropna()\n",
    "features = th.from_numpy(df.drop([\"Date\", \"Trading_Price\", \"Lable\"], axis=1).to_numpy()).to(device=device).type(th.float32)\n",
    "lable = th.from_numpy(df[\"Lable\"].to_numpy()).to(device=device)\n",
    "lable = nn.functional.one_hot(lable, num_classes=2).type(th.float32)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25055, 100]), torch.Size([25055, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, lable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, lable, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "learning_rate = 0.0005\n",
    "\n",
    "model = Network(\n",
    "    n_inputs=features.shape[1],\n",
    "    n_outputs=2,\n",
    "    hidden_size=256,\n",
    "    n_layers=3\n",
    ").to(device=device)\n",
    "\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "optimiser = th.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.693128228187561 | Accuracy: 0.0 | F1: 0\n",
      "Epoch: 100 | Loss: 0.6931772232055664 | Accuracy: 0.0 | F1: 0\n",
      "Epoch: 200 | Loss: 0.6931761503219604 | Accuracy: 0.0 | F1: 0\n",
      "Epoch: 300 | Loss: 0.6931235790252686 | Accuracy: 0.0 | F1: 0\n",
      "Epoch: 400 | Loss: 0.6937114000320435 | Accuracy: 0.0 | F1: 0\n",
      "Epoch: 500 | Loss: 0.6943509578704834 | Accuracy: [0.33333333] | F1: 0.0\n",
      "Epoch: 600 | Loss: 0.6943963766098022 | Accuracy: [0.4] | F1: 0.0\n",
      "Epoch: 700 | Loss: 0.6949750185012817 | Accuracy: [0.5] | F1: 0.0\n",
      "Epoch: 800 | Loss: 0.6952784061431885 | Accuracy: [0.5] | F1: 0.0\n",
      "Epoch: 900 | Loss: 0.6960248947143555 | Accuracy: [0.5] | F1: 0.0\n",
      "Epoch: 1000 | Loss: 0.6958256959915161 | Accuracy: [0.4] | F1: 0.0\n",
      "Epoch: 1100 | Loss: 0.6955059170722961 | Accuracy: [0.5] | F1: 0.0\n",
      "Epoch: 1200 | Loss: 0.6956354975700378 | Accuracy: [0.66666667] | F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Carlos\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1300 | Loss: 0.695771336555481 | Accuracy: [1.] | F1: 0.0\n",
      "Epoch: 1400 | Loss: 0.6958630084991455 | Accuracy: 0.0 | F1: 0\n",
      "Epoch: 1500 | Loss: 0.6960798501968384 | Accuracy: 0.0 | F1: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Carlos\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600 | Loss: 0.6973121166229248 | Accuracy: [1.] | F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Carlos\\anaconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1700 | Loss: 0.6951082348823547 | Accuracy: [1.] | F1: 0.0\n",
      "Epoch: 1800 | Loss: 0.6966803669929504 | Accuracy: [0.66666667] | F1: 0.0\n",
      "Epoch: 1900 | Loss: 0.6981440186500549 | Accuracy: [0.5] | F1: 0.0\n",
      "Epoch: 2000 | Loss: 0.6983193755149841 | Accuracy: [0.4] | F1: 0.0\n",
      "Epoch: 2100 | Loss: 0.6985597610473633 | Accuracy: [0.33333333] | F1: 0.0\n",
      "Epoch: 2200 | Loss: 0.7007835507392883 | Accuracy: [0.33333333] | F1: 0.0\n",
      "Epoch: 2300 | Loss: 0.6987282037734985 | Accuracy: [0.5] | F1: 0.0\n",
      "Epoch: 2400 | Loss: 0.7003363370895386 | Accuracy: [0.5] | F1: 0.0\n",
      "Epoch: 2500 | Loss: 0.7004687190055847 | Accuracy: [0.57142857] | F1: 0.5714285714285715\n",
      "Epoch: 2600 | Loss: 0.699497401714325 | Accuracy: [0.38888889] | F1: 0.42105263157894735\n",
      "Epoch: 2700 | Loss: 0.7005221247673035 | Accuracy: [0.42857143] | F1: 0.4666666666666667\n",
      "Epoch: 2800 | Loss: 0.7011530995368958 | Accuracy: [0.44186047] | F1: 0.45454545454545453\n",
      "Epoch: 2900 | Loss: 0.7018604874610901 | Accuracy: [0.38297872] | F1: 0.3829787234042554\n",
      "Epoch: 3000 | Loss: 0.7017976641654968 | Accuracy: [0.43478261] | F1: 0.5\n",
      "Epoch: 3100 | Loss: 0.7023759484291077 | Accuracy: [0.51239669] | F1: 0.5815602836879432\n",
      "Epoch: 3200 | Loss: 0.7031151652336121 | Accuracy: [0.49382716] | F1: 0.5684210526315788\n",
      "Epoch: 3300 | Loss: 0.7038478255271912 | Accuracy: [0.49456522] | F1: 0.5753424657534246\n",
      "Epoch: 3400 | Loss: 0.7046952843666077 | Accuracy: [0.48165138] | F1: 0.5603112840466925\n",
      "Epoch: 3500 | Loss: 0.7049702405929565 | Accuracy: [0.47033898] | F1: 0.5421245421245421\n",
      "Epoch: 3600 | Loss: 0.7057972550392151 | Accuracy: [0.47744361] | F1: 0.5382059800664452\n",
      "Epoch: 3700 | Loss: 0.7065607905387878 | Accuracy: [0.48494983] | F1: 0.5389221556886228\n",
      "Epoch: 3800 | Loss: 0.7075799703598022 | Accuracy: [0.49560117] | F1: 0.5473684210526315\n",
      "Epoch: 3900 | Loss: 0.7087103128433228 | Accuracy: [0.49736842] | F1: 0.5484633569739953\n",
      "Epoch: 4000 | Loss: 0.7094106674194336 | Accuracy: [0.49760766] | F1: 0.5454545454545455\n",
      "Epoch: 4100 | Loss: 0.7092112898826599 | Accuracy: [0.4963145] | F1: 0.5372460496613995\n",
      "Epoch: 4200 | Loss: 0.7104557752609253 | Accuracy: [0.49126638] | F1: 0.5349301397205589\n",
      "Epoch: 4300 | Loss: 0.7111861109733582 | Accuracy: [0.494] | F1: 0.5271028037383177\n",
      "Epoch: 4400 | Loss: 0.7116015553474426 | Accuracy: [0.4921875] | F1: 0.5289855072463768\n",
      "Epoch: 4500 | Loss: 0.7185499668121338 | Accuracy: [0.49398907] | F1: 0.5172054223149113\n",
      "Epoch: 4600 | Loss: 0.711151659488678 | Accuracy: [0.47991543] | F1: 0.4896265560165975\n",
      "Epoch: 4700 | Loss: 0.715901255607605 | Accuracy: [0.49439776] | F1: 0.5686977299880526\n",
      "Epoch: 4800 | Loss: 0.7131803035736084 | Accuracy: [0.48551959] | F1: 0.47931034482758617\n",
      "Epoch: 4900 | Loss: 0.7135151028633118 | Accuracy: [0.4875208] | F1: 0.4797297297297297\n",
      "Epoch: 5000 | Loss: 0.7138229012489319 | Accuracy: [0.48553055] | F1: 0.47019867549668865\n",
      "Epoch: 5100 | Loss: 0.7143777012825012 | Accuracy: [0.48826291] | F1: 0.4682926829268293\n",
      "Epoch: 5200 | Loss: 0.7148803472518921 | Accuracy: [0.47734139] | F1: 0.45425867507886436\n",
      "Epoch: 5300 | Loss: 0.7151983380317688 | Accuracy: [0.47845468] | F1: 0.45412130637636083\n",
      "Epoch: 5400 | Loss: 0.7157561779022217 | Accuracy: [0.46573427] | F1: 0.44314868804664725\n",
      "Epoch: 5500 | Loss: 0.7162915468215942 | Accuracy: [0.46308725] | F1: 0.4428969359331476\n",
      "Epoch: 5600 | Loss: 0.7173739671707153 | Accuracy: [0.46894804] | F1: 0.4702907711757269\n",
      "Epoch: 5700 | Loss: 0.7146186232566833 | Accuracy: [0.47968545] | F1: 0.49037227214377405\n",
      "Epoch: 5800 | Loss: 0.7155810594558716 | Accuracy: [0.45790251] | F1: 0.474964234620887\n",
      "Epoch: 5900 | Loss: 0.7217047214508057 | Accuracy: [0.47633434] | F1: 0.5886075949367088\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m lossfn(y_pred, y_train)\n\u001b[0;32m      6\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m----> 7\u001b[0m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), [grads]) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m foreach) \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(grads, device\u001b[38;5;241m=\u001b[39mdevice):\n\u001b[1;32m---> 76\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_coef_clamped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    y_pred = model(X_train)\n",
    "    optimiser.zero_grad()\n",
    "    loss = lossfn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    th.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "    optimiser.step()\n",
    "    \n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        model.eval()\n",
    "        with th.inference_mode():\n",
    "            y_pred = model(X_test)\n",
    "        confident_indices = np.where(y_pred.cpu() >= confidence_threshold)[0]   \n",
    "        pred_filtered = y_test.argmax(dim=1).unsqueeze(dim=1).cpu()[confident_indices].detach().cpu().numpy()\n",
    "        test_filtered = th.argmax(y_pred, dim=1).unsqueeze(dim=1).cpu()[confident_indices].detach().cpu().numpy()\n",
    "        acc = sum(pred_filtered == test_filtered) / max(len(y_pred[confident_indices]), 1)\n",
    "        try:\n",
    "            f1 = f1_score(test_filtered, pred_filtered)\n",
    "        except:  # noqa: E722 ik this bad, but it works\n",
    "            f1 = 0\n",
    "        loss = lossfn(y_pred, y_test)\n",
    "        \n",
    "        print(f\"Epoch: {epoch} | Loss: {loss} | Accuracy: {acc} | F1: {f1}\")\n",
    "        \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(model, \"models/supervised_02.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1 and 6x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 16\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Carlos\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1 and 6x256)"
     ]
    }
   ],
   "source": [
    "model.forward(th.Tensor([[0]]).to(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15bc25b7250>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = th.linspace(0, 0.002, 10000)\n",
    "y, pred = model.forward(x.unsqueeze(dim=1).to(device=device)).max(dim=1)\n",
    "y = y.detach().cpu().numpy()\n",
    "pred = pred.detach().cpu().numpy()\n",
    "plt.scatter(x, y, c=pred)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    75223.000000\n",
       "mean         0.000242\n",
       "std          0.000281\n",
       "min          0.000000\n",
       "25%          0.000073\n",
       "50%          0.000165\n",
       "75%          0.000319\n",
       "max          0.008235\n",
       "Name: 15m_x5_0, dtype: float64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"15m_x5_0\"].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
